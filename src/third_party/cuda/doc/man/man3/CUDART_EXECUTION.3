.TH "Execution Control" 3 "12 Jan 2017" "Version 6.0" "Doxygen" \" -*- nroff -*-
.ad l
.nh
.SH NAME
Execution Control \- 
.SS "Functions"

.in +1c
.ti -1c
.RI "__cudart_builtin__ \fBcudaError_t\fP \fBcudaFuncGetAttributes\fP (struct \fBcudaFuncAttributes\fP *attr, const void *func)"
.br
.RI "\fIFind out attributes for a given function. \fP"
.ti -1c
.RI "\fBcudaError_t\fP \fBcudaFuncSetCacheConfig\fP (const void *func, enum \fBcudaFuncCache\fP cacheConfig)"
.br
.RI "\fISets the preferred cache configuration for a device function. \fP"
.ti -1c
.RI "\fBcudaError_t\fP \fBcudaFuncSetSharedMemConfig\fP (const void *func, enum \fBcudaSharedMemConfig\fP config)"
.br
.RI "\fISets the shared memory configuration for a device function. \fP"
.ti -1c
.RI "__device__ __cudart_builtin__ void * \fBcudaGetParameterBuffer\fP (size_t alignment, size_t size)"
.br
.RI "\fIObtains a parameter buffer. \fP"
.ti -1c
.RI "__device__ __cudart_builtin__ void * \fBcudaGetParameterBufferV2\fP (void *func, dim3 gridDimension, dim3 blockDimension, unsigned int sharedMemSize)"
.br
.RI "\fILaunches a specified kernel. \fP"
.ti -1c
.RI "\fBcudaError_t\fP \fBcudaLaunchKernel\fP (const void *func, dim3 gridDim, dim3 blockDim, void **args, size_t sharedMem, \fBcudaStream_t\fP stream)"
.br
.RI "\fILaunches a device function. \fP"
.ti -1c
.RI "\fBcudaError_t\fP \fBcudaSetDoubleForDevice\fP (double *d)"
.br
.RI "\fIConverts a double argument to be executed on a device. \fP"
.ti -1c
.RI "\fBcudaError_t\fP \fBcudaSetDoubleForHost\fP (double *d)"
.br
.RI "\fIConverts a double argument after execution on a device. \fP"
.in -1c
.SH "Detailed Description"
.PP 
\\brief execution control functions of the CUDA runtime API (cuda_runtime_api.h)
.PP
This section describes the execution control functions of the CUDA runtime application programming interface.
.PP
Some functions have overloaded C++ API template versions documented separately in the \fBC++ API Routines\fP module. 
.SH "Function Documentation"
.PP 
.SS "__cudart_builtin__ \fBcudaError_t\fP cudaFuncGetAttributes (struct \fBcudaFuncAttributes\fP * attr, const void * func)"
.PP
This function obtains the attributes of a function specified via \fCfunc\fP. \fCfunc\fP is a device function symbol and must be declared as a \fC__global__\fP function. The fetched attributes are placed in \fCattr\fP. If the specified function does not exist, then \fBcudaErrorInvalidDeviceFunction\fP is returned. For templated functions, pass the function symbol as follows: func_name<template_arg_0,...,template_arg_N>
.PP
Note that some function attributes such as \fBmaxThreadsPerBlock\fP may vary based on the device that is currently being used.
.PP
\fBParameters:\fP
.RS 4
\fIattr\fP - Return pointer to function's attributes 
.br
\fIfunc\fP - Device function symbol
.RE
.PP
\fBReturns:\fP
.RS 4
\fBcudaSuccess\fP, \fBcudaErrorInitializationError\fP, \fBcudaErrorInvalidDeviceFunction\fP 
.RE
.PP
\fBNote:\fP
.RS 4
Note that this function may also return error codes from previous, asynchronous launches. 
.PP
Use of a string naming a function as the \fCfunc\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
.RE
.PP
\fBSee also:\fP
.RS 4
\fBcudaConfigureCall\fP, \fBcudaFuncSetCacheConfig (C API)\fP, \fBcudaFuncGetAttributes (C++ API)\fP, \fBcudaLaunchKernel (C API)\fP, \fBcudaSetDoubleForDevice\fP, \fBcudaSetDoubleForHost\fP, \fBcudaSetupArgument (C API)\fP 
.RE
.PP

.SS "\fBcudaError_t\fP cudaFuncSetCacheConfig (const void * func, enum \fBcudaFuncCache\fP cacheConfig)"
.PP
On devices where the L1 cache and shared memory use the same hardware resources, this sets through \fCcacheConfig\fP the preferred cache configuration for the function specified via \fCfunc\fP. This is only a preference. The runtime will use the requested configuration if possible, but it is free to choose a different configuration if required to execute \fCfunc\fP.
.PP
\fCfunc\fP is a device function symbol and must be declared as a \fC__global__\fP function. If the specified function does not exist, then \fBcudaErrorInvalidDeviceFunction\fP is returned. For templated functions, pass the function symbol as follows: func_name<template_arg_0,...,template_arg_N>
.PP
This setting does nothing on devices where the size of the L1 cache and shared memory are fixed.
.PP
Launching a kernel with a different preference than the most recent preference setting may insert a device-side synchronization point.
.PP
The supported cache configurations are:
.IP "\(bu" 2
\fBcudaFuncCachePreferNone\fP: no preference for shared memory or L1 (default)
.IP "\(bu" 2
\fBcudaFuncCachePreferShared\fP: prefer larger shared memory and smaller L1 cache
.IP "\(bu" 2
\fBcudaFuncCachePreferL1\fP: prefer larger L1 cache and smaller shared memory
.IP "\(bu" 2
\fBcudaFuncCachePreferEqual\fP: prefer equal size L1 cache and shared memory
.PP
.PP
\fBParameters:\fP
.RS 4
\fIfunc\fP - Device function symbol 
.br
\fIcacheConfig\fP - Requested cache configuration
.RE
.PP
\fBReturns:\fP
.RS 4
\fBcudaSuccess\fP, \fBcudaErrorInitializationError\fP, \fBcudaErrorInvalidDeviceFunction\fP 
.RE
.PP
\fBNote:\fP
.RS 4
Note that this function may also return error codes from previous, asynchronous launches. 
.PP
Use of a string naming a function as the \fCfunc\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
.RE
.PP
\fBSee also:\fP
.RS 4
\fBcudaConfigureCall\fP, \fBcudaFuncSetCacheConfig (C++ API)\fP, \fBcudaFuncGetAttributes (C API)\fP, \fBcudaLaunchKernel (C API)\fP, \fBcudaSetDoubleForDevice\fP, \fBcudaSetDoubleForHost\fP, \fBcudaSetupArgument (C API)\fP, \fBcudaThreadGetCacheConfig\fP, \fBcudaThreadSetCacheConfig\fP 
.RE
.PP

.SS "\fBcudaError_t\fP cudaFuncSetSharedMemConfig (const void * func, enum \fBcudaSharedMemConfig\fP config)"
.PP
On devices with configurable shared memory banks, this function will force all subsequent launches of the specified device function to have the given shared memory bank size configuration. On any given launch of the function, the shared memory configuration of the device will be temporarily changed if needed to suit the function's preferred configuration. Changes in shared memory configuration between subsequent launches of functions, may introduce a device side synchronization point.
.PP
Any per-function setting of shared memory bank size set via \fBcudaFuncSetSharedMemConfig\fP will override the device wide setting set by \fBcudaDeviceSetSharedMemConfig\fP.
.PP
Changing the shared memory bank size will not increase shared memory usage or affect occupancy of kernels, but may have major effects on performance. Larger bank sizes will allow for greater potential bandwidth to shared memory, but will change what kinds of accesses to shared memory will result in bank conflicts.
.PP
This function will do nothing on devices with fixed shared memory bank size.
.PP
For templated functions, pass the function symbol as follows: func_name<template_arg_0,...,template_arg_N>
.PP
The supported bank configurations are:
.IP "\(bu" 2
cudaSharedMemBankSizeDefault: use the device's shared memory configuration when launching this function.
.IP "\(bu" 2
cudaSharedMemBankSizeFourByte: set shared memory bank width to be four bytes natively when launching this function.
.IP "\(bu" 2
cudaSharedMemBankSizeEightByte: set shared memory bank width to be eight bytes natively when launching this function.
.PP
.PP
\fBParameters:\fP
.RS 4
\fIfunc\fP - Device function symbol 
.br
\fIconfig\fP - Requested shared memory configuration
.RE
.PP
\fBReturns:\fP
.RS 4
\fBcudaSuccess\fP, \fBcudaErrorInitializationError\fP, \fBcudaErrorInvalidDeviceFunction\fP, \fBcudaErrorInvalidValue\fP, 
.RE
.PP
\fBNote:\fP
.RS 4
Note that this function may also return error codes from previous, asynchronous launches. 
.PP
Use of a string naming a function as the \fCfunc\fP paramater was deprecated in CUDA 4.1 and removed in CUDA 5.0.
.RE
.PP
\fBSee also:\fP
.RS 4
\fBcudaConfigureCall\fP, \fBcudaDeviceSetSharedMemConfig\fP, \fBcudaDeviceGetSharedMemConfig\fP, \fBcudaDeviceSetCacheConfig\fP, \fBcudaDeviceGetCacheConfig\fP, \fBcudaFuncSetCacheConfig\fP 
.RE
.PP

.SS "__device__ __cudart_builtin__ void* cudaGetParameterBuffer (size_t alignment, size_t size)"
.PP
Obtains a parameter buffer which can be filled with parameters for a kernel launch. Parameters passed to cudaLaunchDevice must be allocated via this function.
.PP
This is a low level API and can only be accessed from Parallel Thread Execution (PTX). CUDA user code should use <<< >>> to launch kernels.
.PP
\fBParameters:\fP
.RS 4
\fIalignment\fP - Specifies alignment requirement of the parameter buffer 
.br
\fIsize\fP - Specifies size requirement in bytes
.RE
.PP
\fBReturns:\fP
.RS 4
Returns pointer to the allocated parameterBuffer 
.RE
.PP
\fBNote:\fP
.RS 4
Note that this function may also return error codes from previous, asynchronous launches.
.RE
.PP
\fBSee also:\fP
.RS 4
cudaLaunchDevice 
.RE
.PP

.SS "__device__ __cudart_builtin__ void* cudaGetParameterBufferV2 (void * func, dim3 gridDimension, dim3 blockDimension, unsigned int sharedMemSize)"
.PP
Launches a specified kernel with the specified parameter buffer. A parameter buffer can be obtained by calling \fBcudaGetParameterBuffer()\fP.
.PP
This is a low level API and can only be accessed from Parallel Thread Execution (PTX). CUDA user code should use <<< >>> to launch the kernels.
.PP
\fBParameters:\fP
.RS 4
\fIfunc\fP - Pointer to the kernel to be launched 
.br
\fIparameterBuffer\fP - Holds the parameters to the launched kernel. parameterBuffer can be NULL. (Optional) 
.br
\fIgridDimension\fP - Specifies grid dimensions 
.br
\fIblockDimension\fP - Specifies block dimensions 
.br
\fIsharedMemSize\fP - Specifies size of shared memory 
.br
\fIstream\fP - Specifies the stream to be used
.RE
.PP
\fBReturns:\fP
.RS 4
\fBcudaSuccess\fP, \fBcudaErrorInvalidDevice\fP, \fBcudaErrorLaunchMaxDepthExceeded\fP, \fBcudaErrorInvalidConfiguration\fP, \fBcudaErrorStartupFailure\fP, \fBcudaErrorLaunchPendingCountExceeded\fP, \fBcudaErrorLaunchOutOfResources\fP 
.RE
.PP
\fBNote:\fP
.RS 4
Note that this function may also return error codes from previous, asynchronous launches. 
.br
 Please refer to Execution Configuration and Parameter Buffer Layout from the CUDA Programming Guide for the detailed descriptions of launch configuration and parameter layout respectively.
.RE
.PP
\fBSee also:\fP
.RS 4
\fBcudaGetParameterBuffer\fP 
.RE
.PP

.SS "\fBcudaError_t\fP cudaLaunchKernel (const void * func, dim3 gridDim, dim3 blockDim, void ** args, size_t sharedMem, \fBcudaStream_t\fP stream)"
.PP
The function invokes kernel \fCfunc\fP on \fCgridDim\fP (\fCgridDim.x\fP × \fCgridDim.y\fP × \fCgridDim.z\fP) grid of blocks. Each block contains \fCblockDim\fP (\fCblockDim.x\fP × \fCblockDim.y\fP × \fCblockDim.z\fP) threads.
.PP
If the kernel has N parameters the \fCargs\fP should point to array of N pointers. Each pointer, from \fCargs[0]\fP to \fCargs[N - 1]\fP, point to the region of memory from which the actual parameter will be copied.
.PP
For templated functions, pass the function symbol as follows: func_name<template_arg_0,...,template_arg_N>
.PP
\fCsharedMem\fP sets the amount of dynamic shared memory that will be available to each thread block.
.PP
\fCstream\fP specifies a stream the invocation is associated to.
.PP
\fBParameters:\fP
.RS 4
\fIfunc\fP - Device function symbol 
.br
\fIgridDim\fP - Grid dimentions 
.br
\fIblockDim\fP - Block dimentions 
.br
\fIargs\fP - Arguments 
.br
\fIsharedMem\fP - Shared memory 
.br
\fIstream\fP - Stream identifier
.RE
.PP
\fBReturns:\fP
.RS 4
\fBcudaSuccess\fP, \fBcudaErrorInvalidDeviceFunction\fP, \fBcudaErrorInvalidConfiguration\fP, \fBcudaErrorLaunchFailure\fP, \fBcudaErrorLaunchTimeout\fP, \fBcudaErrorLaunchOutOfResources\fP, \fBcudaErrorSharedObjectInitFailed\fP 
.RE
.PP
\fBNote:\fP
.RS 4
This function uses standard  semantics. 
.PP
Note that this function may also return error codes from previous, asynchronous launches.
.RE
.PP
\fBcudaLaunchKernel (C++ API)\fP 
.SS "\fBcudaError_t\fP cudaSetDoubleForDevice (double * d)"
.PP
\fBParameters:\fP
.RS 4
\fId\fP - Double to convert
.RE
.PP
\fBDeprecated\fP
.RS 4
This function is deprecated as of CUDA 7.5
.RE
.PP
Converts the double value of \fCd\fP to an internal float representation if the device does not support double arithmetic. If the device does natively support doubles, then this function does nothing.
.PP
\fBReturns:\fP
.RS 4
\fBcudaSuccess\fP 
.RE
.PP
\fBNote:\fP
.RS 4
Note that this function may also return error codes from previous, asynchronous launches.
.RE
.PP
\fBcudaLaunch (C API)\fP, \fBcudaFuncSetCacheConfig (C API)\fP, \fBcudaFuncGetAttributes (C API)\fP, \fBcudaSetDoubleForHost\fP, \fBcudaSetupArgument (C API)\fP 
.SS "\fBcudaError_t\fP cudaSetDoubleForHost (double * d)"
.PP
\fBDeprecated\fP
.RS 4
This function is deprecated as of CUDA 7.5
.RE
.PP
Converts the double value of \fCd\fP from a potentially internal float representation if the device does not support double arithmetic. If the device does natively support doubles, then this function does nothing.
.PP
\fBParameters:\fP
.RS 4
\fId\fP - Double to convert
.RE
.PP
\fBReturns:\fP
.RS 4
\fBcudaSuccess\fP 
.RE
.PP
\fBNote:\fP
.RS 4
Note that this function may also return error codes from previous, asynchronous launches.
.RE
.PP
\fBcudaLaunch (C API)\fP, \fBcudaFuncSetCacheConfig (C API)\fP, \fBcudaFuncGetAttributes (C API)\fP, \fBcudaSetDoubleForDevice\fP, \fBcudaSetupArgument (C API)\fP 
.SH "Author"
.PP 
Generated automatically by Doxygen from the source code.
